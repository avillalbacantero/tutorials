{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_tutorial_08_load_save_models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load and save models\n",
        "\n",
        "A model consists of:\n",
        "- An architecture\n",
        "- The weights (the state of the model)\n",
        "- An optimizer -> this enables restart training where you left)\n",
        "- A set of losses and metrics\n",
        "\n",
        "Using the Keras API you can:\n",
        "- Save everything (TF SavedModel) (standard practice)\n",
        "- Save the architecture (JSON)\n",
        "- Save the weights (when training)"
      ],
      "metadata": {
        "id": "QHztI7ZrF2Mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "G5tgrrGtGz1u"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Saving everything\n",
        "You can use:\n",
        "- TensorFlow SavedModel format.\n",
        "- Keras G5 format (old)."
      ],
      "metadata": {
        "id": "Pz6Tx1ozHPJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensorFlow SavedModel:"
      ],
      "metadata": {
        "id": "XNkj-hZoKnrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's define a model architecture\n",
        "def get_model():\n",
        "    # Create a simple model.\n",
        "    inputs = keras.Input(shape=(32,))\n",
        "    outputs = keras.layers.Dense(1)(inputs)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "jheyzCmNHcTq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imagine that now you train the model\n",
        "model = get_model()\n",
        "\n",
        "test_input = np.random.random((128, 32))\n",
        "test_target = np.random.random((128, 1))\n",
        "model.fit(test_input, test_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "davrmdl2HhXi",
        "outputId": "ae01d0b0-3d74-4ea6-e97f-d87fef000d61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3941\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45e775b750>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Once the model is trained, you can save everything in SaveModel format like\n",
        "# follows:\n",
        "model.save(\"my_model\")  # creates a folder 'my_model'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc8wVUOFHo6r",
        "outputId": "a9cb3076-b4a2-453a-9b1a-db578909aab4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: my_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To load the saved model, you can do:\n",
        "reconstructed_model = keras.models.load_model(\"my_model\")\n",
        "\n",
        "# Test:\n",
        "np.testing.assert_allclose(\n",
        "    model.predict(test_input), reconstructed_model.predict(test_input)\n",
        ")\n"
      ],
      "metadata": {
        "id": "M4xWuWSoH2Rs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the optimizer has been saved too, you can resume training:\n",
        "reconstructed_model.fit(test_input, test_target)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiSAhez1ICwY",
        "outputId": "eb66e72d-087c-468a-9f61-3b1219f493b5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2508\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45e7435cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's inspect what is in the folder:\n",
        "%ls my_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb47UQZpILo_",
        "outputId": "fec45559-cffb-42cf-c2d7-4645518b52d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/  keras_metadata.pb  saved_model.pb  \u001b[01;34mvariables\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- saved_model.pb -> model architecture + training configuration (optimizer, losses, metrics)\n",
        "- variables/ -> model weights"
      ],
      "metadata": {
        "id": "zKSGP4ztIWgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Saving custom models:\n",
        "When saving the model and its layers, the SavedModel format stores the class name, call function, losses, and weights (and the config, if implemented). It is always a good practice to define the get_config and from_config methods when writing a custom model or layer class."
      ],
      "metadata": {
        "id": "qB667P2EJcrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom model\n",
        "class CustomModel(keras.Model):\n",
        "    def __init__(self, hidden_units):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.hidden_units = hidden_units\n",
        "        self.dense_layers = [keras.layers.Dense(u) for u in hidden_units]\n",
        "\n",
        "    def call(self, inputs):\n",
        "      \"\"\"The call defines the computation graph of the model\"\"\"\n",
        "      x = inputs\n",
        "      for layer in self.dense_layers:\n",
        "          x = layer(x)\n",
        "      return x\n",
        "\n",
        "    # Let's define 'get_config' and 'from_config' methods to load and save this\n",
        "    # custom model\n",
        "    def get_config(self):\n",
        "        return {\"hidden_units\": self.hidden_units}\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "# Try the model with an input\n",
        "model = CustomModel([16, 16, 10])\n",
        "# Build the model by calling it\n",
        "input_arr = tf.random.uniform((1, 5))\n",
        "outputs = model(input_arr)\n",
        "\n",
        "# And save the model\n",
        "model.save(\"my_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZn5BBn2Jm0L",
        "outputId": "840d0261-9c3d-46ea-98c8-88fc9dd96496"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: my_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 1: Load the model with 'custom_object':\n",
        "loaded_1 = keras.models.load_model(\n",
        "    \"my_model\", custom_objects={\"CustomModel\": CustomModel}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nf6SXO9KFGe",
        "outputId": "28c3e9fd-1e88-4a14-bf8b-4e5c04a15ea1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 2: Load the model without the CustomClass\n",
        "del CustomModel\n",
        "loaded_2 = keras.models.load_model(\"my_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHMubHK7KJ_K",
        "outputId": "d9b4f8ec-2ad8-447f-9051-54170078dcc4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test both models\n",
        "np.testing.assert_allclose(loaded_1(input_arr), outputs)\n",
        "np.testing.assert_allclose(loaded_2(input_arr), outputs)"
      ],
      "metadata": {
        "id": "jRyqD0wYKQas"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keras H5 format (old)"
      ],
      "metadata": {
        "id": "u6SBZ-drKsai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "\n",
        "test_input = np.random.random((128, 32))\n",
        "test_target = np.random.random((128, 1))\n",
        "model.fit(test_input, test_target)\n",
        "\n",
        "# Since we are giving the 'h5' extension, the model will be saved using HF5.\n",
        "model.save(\"my_h5_model.h5\")\n",
        "\n",
        "# Again, we can load the model from disk\n",
        "reconstructed_model = keras.models.load_model(\"my_h5_model.h5\")\n",
        "\n",
        "# Test\n",
        "np.testing.assert_allclose(\n",
        "    model.predict(test_input), reconstructed_model.predict(test_input)\n",
        ")\n",
        "\n",
        "# Again, training can be resume:\n",
        "reconstructed_model.fit(test_input, test_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEkIi1DdKu3t",
        "outputId": "11171c84-995d-464a-d04b-4a8c79f22f20"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3436\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3047\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45e4a2b650>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's recommended to use TF SavedModel instead of Keras H5."
      ],
      "metadata": {
        "id": "sjCljkSGLTV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Saving the architecture\n",
        "\n",
        "This applies to model defined using the Sequential or Functional APIs, not subclassed."
      ],
      "metadata": {
        "id": "oVYMuFJ9Lash"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_config(), from_config()"
      ],
      "metadata": {
        "id": "0jRm5sY7Mjwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Sequential model\n",
        "\n",
        "# Let's define a sequential model\n",
        "model = keras.Sequential([keras.Input((32,)), keras.layers.Dense(1)])\n",
        "\n",
        "# Get the config (architecture)\n",
        "config = model.get_config()\n",
        "\n",
        "# From that config, create a new identical architecture\n",
        "new_model = keras.Sequential.from_config(config)\n",
        "\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hChrKyGLwku",
        "outputId": "d054aa40-a5db-4f71-f898-2711fa72356b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 32),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'input_3',\n",
              "    'ragged': False,\n",
              "    'sparse': False}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'linear',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_8',\n",
              "    'trainable': True,\n",
              "    'units': 1,\n",
              "    'use_bias': True}}],\n",
              " 'name': 'sequential'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Functional model\n",
        "\n",
        "# Let's define a model\n",
        "inputs = keras.Input((32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Get the config (architecture)\n",
        "config = model.get_config()\n",
        "\n",
        "# From that config, create a new identical architecture\n",
        "new_model = keras.Model.from_config(config)\n",
        "\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giO2YTx6ME7F",
        "outputId": "b429a375-d64b-4966-9b70-e997745c3ac3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_layers': [['input_4', 0, 0]],\n",
              " 'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 32),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'input_4',\n",
              "    'ragged': False,\n",
              "    'sparse': False},\n",
              "   'inbound_nodes': [],\n",
              "   'name': 'input_4'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'linear',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_9',\n",
              "    'trainable': True,\n",
              "    'units': 1,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['input_4', 0, 0, {}]]],\n",
              "   'name': 'dense_9'}],\n",
              " 'name': 'model_2',\n",
              " 'output_layers': [['dense_9', 0, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Layer\n",
        "\n",
        "\n",
        "# Let's define a layer\n",
        "layer = keras.layers.Dense(3, activation=\"relu\")\n",
        "\n",
        "# Get the config (architecture)\n",
        "layer_config = layer.get_config()\n",
        "\n",
        "# From that config, create a new identical architecture\n",
        "new_layer = keras.layers.Dense.from_config(layer_config)\n",
        "\n",
        "layer_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dwvQG3vMSUU",
        "outputId": "ebf5afdd-197c-46fd-be71-fee005308d34"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'activity_regularizer': None,\n",
              " 'bias_constraint': None,\n",
              " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              " 'bias_regularizer': None,\n",
              " 'dtype': 'float32',\n",
              " 'kernel_constraint': None,\n",
              " 'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "  'config': {'seed': None}},\n",
              " 'kernel_regularizer': None,\n",
              " 'name': 'dense_10',\n",
              " 'trainable': True,\n",
              " 'units': 3,\n",
              " 'use_bias': True}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSON\n",
        "\n",
        "This is similar to get_config and from_config, but the model can be loaded without the original model class."
      ],
      "metadata": {
        "id": "kO9kUjjMModg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model, for example a Sequential one\n",
        "model = keras.Sequential([keras.Input((32,)), keras.layers.Dense(1)])\n",
        "\n",
        "# Export the model architecture to JSON\n",
        "json_config = model.to_json()\n",
        "\n",
        "# Load the architecture from the JSON. You don't need to know the model is a \n",
        "# Sequential one.\n",
        "new_model = keras.models.model_from_json(json_config)\n",
        "\n",
        "json_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "YUkmevAYM0T_",
        "outputId": "2f2ee16f-8ee3-4537-e8ca-4cae06d3db49"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_1\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 32], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"input_5\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_11\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.7.0\", \"backend\": \"tensorflow\"}'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Custom objects\n",
        "\n",
        "TODO: When studying https://www.tensorflow.org/guide/keras/custom_layers_and_models"
      ],
      "metadata": {
        "id": "C07f6VtbNFqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Saving the weights\n",
        "\n",
        "This is useful for:\n",
        "- Inference\n",
        "- Transfer Learning\n"
      ],
      "metadata": {
        "id": "OItVESiZSiZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Transfering weights from one layer to another\n",
        "\n",
        "def create_layer():\n",
        "  layer = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")\n",
        "  layer.build((None, 784))\n",
        "  return layer\n",
        "\n",
        "layer1 = create_layer()\n",
        "layer2 = create_layer()\n",
        "\n",
        "layer2.set_weights(layer1.get_weights())"
      ],
      "metadata": {
        "id": "EQ9KdW4NSxC6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Transfering weights from one model to another\n",
        "\n",
        "def create_model():\n",
        "  inputs = keras.Input(shape=(784,), name=\"digits\")\n",
        "  x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "  x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_12\")(x)\n",
        "  outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
        "  functional_model = keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
        "  return functional_model\n",
        "\n",
        "model1 = create_model()\n",
        "model2 = create_model()\n",
        "\n",
        "# Call one model to create the weights\n",
        "dummy_input = tf.ones((1,784))\n",
        "model1(dummy_input)\n",
        "\n",
        "# Copy weights\n",
        "model2.set_weights(model1.get_weights())\n",
        "\n",
        "assert len(model1.weights) == len(model2.weights)\n",
        "for a, b in zip(model1.weights, model2.weights):\n",
        "    np.testing.assert_allclose(a.numpy(), b.numpy())"
      ],
      "metadata": {
        "id": "0VTlWvmKTVgb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stateless layer do not affect to weight transfering."
      ],
      "metadata": {
        "id": "wUWtPLu_V5CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_with_stateless_layer():\n",
        "  \"\"\"Same model as before but with a dropout layer\"\"\"\n",
        "  inputs = keras.Input(shape=(784,), name=\"digits\")\n",
        "  x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "  x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_12\")(x)\n",
        "  x = keras.layers.Dropout(0.5)(x)\n",
        "  outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
        "  functional_model = keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
        "  return functional_model\n",
        "\n",
        "model1 = create_model()\n",
        "model2 = create_model_with_stateless_layer()\n",
        "\n",
        "# Call one model to create the weights\n",
        "dummy_input = tf.ones((1,784))\n",
        "model1(dummy_input)\n",
        "\n",
        "# Copy weights\n",
        "model2.set_weights(model1.get_weights())\n",
        "\n",
        "assert len(model1.weights) == len(model2.weights)\n",
        "for a, b in zip(model1.weights, model2.weights):\n",
        "    np.testing.assert_allclose(a.numpy(), b.numpy())"
      ],
      "metadata": {
        "id": "Dklzch-tV9_P"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can save model's weights in two different formats:\n",
        "- TensorFlow checkpoint\n",
        "- HDF5\n",
        "\n",
        "We can use 'save_format' argument or the output extension to specify the format.\n",
        "\n",
        "### TensorFlow checkpoints"
      ],
      "metadata": {
        "id": "DSIc-_j4WYHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF Checkpoint format\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.save_weights(\"ckpt\")  # save weights\n",
        "load_status = model.load_weights(\"ckpt\")  # load weights\n",
        "\n",
        "# Assert that all variables have been restored from \n",
        "# the checkpoint\n",
        "load_status.assert_consumed()"
      ],
      "metadata": {
        "id": "5HcK-akUWnKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3eb45e-48cc-484a-d416-329b80f2c2d9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f45e4a97990>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see a Transfer Learning example\n",
        "\n",
        "# First, we instanciate our previosly used model\n",
        "model = create_model()\n",
        "\n",
        "# Then, we create another similar model that excludes the final layer\n",
        "pretrained_model = keras.Model(model.inputs, model.layers[-1].input, name=\"pretrained_model\")\n",
        "\n",
        "# And assign random weights (to simulate pretraining)\n",
        "for w in pretrained_model.weights:\n",
        "  w.assign(tf.random.normal(w.shape))\n",
        "pretrained_model.save_weights(\"pretrained_ckpt\")\n",
        "pretrained_model.summary()\n",
        "\n",
        "# Now, we have a new model that shares the backbone with the pretrained one\n",
        "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
        "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
        "outputs = keras.layers.Dense(5, name=\"predictions\")(x)\n",
        "new_model = keras.Model(inputs=inputs, outputs=outputs, name=\"new_model\")\n",
        "\n",
        "# Since the only different layer is the last one, which is not saved on the\n",
        "# pretrained checkpoint, we can load the pretrained weights\n",
        "new_model.load_weights(\"pretrained_ckpt\")\n",
        "new_model.summary()\n",
        "\n",
        "# assert all of the pretrained weights have been loaded\n",
        "for a, b in zip(pretrained_model.weights, new_model.weights):\n",
        "    np.testing.assert_allclose(a.numpy(), b.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n30HYDNoXm-C",
        "outputId": "3aefbe39-fd3b-4f04-abf2-7d2d6d6cdd39"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"pretrained_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " digits (InputLayer)         [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,400\n",
            "Trainable params: 54,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"new_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " digits (InputLayer)         [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,725\n",
            "Trainable params: 54,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Same example but using the Sequential API\n",
        "\n",
        "# Define a sequential model that shares the backbone with the pretrained one\n",
        "model = keras.Sequential([pretrained_model, keras.layers.Dense(5, name=\"predictions\")])\n",
        "\n",
        "# Now, load the weights. Note here that we are using the pretrained_model\n",
        "pretrained_model.load_weights(\"pretrained_ckpt\")\n",
        "# model.load_weights(\"pretrained_ckpt\") -> this wont work\n",
        "\n",
        "# assert the weights\n",
        "# assert all of the pretrained weights have been loaded\n",
        "for a, b in zip(pretrained_model.weights, model.weights):\n",
        "    np.testing.assert_allclose(a.numpy(), b.numpy())\n",
        "\n",
        "pretrained_model.summary()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LalKZ25aZbzn",
        "outputId": "c55d6746-49a6-4641-e519-9f70d95a9768"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"pretrained_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " digits (InputLayer)         [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,400\n",
            "Trainable params: 54,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pretrained_model (Functiona  (None, 64)               54400     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,725\n",
            "Trainable params: 54,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is generally recommended to stick to the same API for building models."
      ],
      "metadata": {
        "id": "YsDxPISEairt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use tf.train.Checkpoint to save and restore exact layers/variables."
      ],
      "metadata": {
        "id": "aSSdmVi_dYit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model, and save the weights of the first and last layers.\n",
        "init_model = create_model()\n",
        "first_dense = init_model.layers[1]\n",
        "last_dense = init_model.layers[-1]\n",
        "ckpt_path = tf.train.Checkpoint(\n",
        "    dense=first_dense,\n",
        "    kernel=last_dense.kernel,\n",
        "    bias=last_dense.bias\n",
        ").save(\"ckpt\")\n",
        "\n",
        "# Define another model with the same first and last layers\n",
        "class ContrivedModel(keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ContrivedModel, self).__init__()\n",
        "        self.first_dense = keras.layers.Dense(64)\n",
        "        self.kernel = self.add_variable(\"kernel\", shape=(64, 10))\n",
        "        self.bias = self.add_variable(\"bias\", shape=(10,))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.first_dense(inputs)\n",
        "        return tf.matmul(x, self.kernel) + self.bias\n",
        "\n",
        "model = ContrivedModel()\n",
        "_ = model(tf.ones((1, 784)))  # create the variables of the dense layer\n",
        "\n",
        "# And load the previous weights\n",
        "tf.train.Checkpoint(\n",
        "    dense=model.first_dense,\n",
        "    kernel=model.kernel,\n",
        "    bias=model.bias\n",
        ").restore(ckpt_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sah1R4Sde2M",
        "outputId": "6c5952f1-a630-49b4-f7a5-0492230a012b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f45e0ce1790>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HDF5 format\n",
        "\n",
        "A model can use a hdf5 checkpoint if it has the same layers and trainable statuses as saved in the checkpoint."
      ],
      "metadata": {
        "id": "NLAmxe4de7gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sequential model\n",
        "sequential_model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(784,), name=\"digits\"),\n",
        "        keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\"),\n",
        "        keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\"),\n",
        "        keras.layers.Dense(10, name=\"predictions\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# To load and save the weights in HDF5 we use:\n",
        "sequential_model.save_weights(\"weights.h5\")\n",
        "sequential_model.load_weights(\"weights.h5\")"
      ],
      "metadata": {
        "id": "eL7TmKpifJmQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing layer.trainable may result in a different layer.weights ordering when the model contains nested layers."
      ],
      "metadata": {
        "id": "dLoUD93If9MA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NestedDenseLayer(keras.layers.Layer):\n",
        "    def __init__(self, units, name=None):\n",
        "        super(NestedDenseLayer, self).__init__(name=name)\n",
        "        self.dense_1 = keras.layers.Dense(units, name=\"dense_1\")\n",
        "        self.dense_2 = keras.layers.Dense(units, name=\"dense_2\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.dense_2(self.dense_1(inputs))\n",
        "\n",
        "# Print model's weights\n",
        "nested_model = keras.Sequential([keras.Input((784,)), NestedDenseLayer(10, \"nested\")])\n",
        "variable_names = [v.name for v in nested_model.weights]\n",
        "print(variable_names)\n",
        "\n",
        "# Set one layer as not trainable, and print model's weights again\n",
        "nested_model.get_layer(\"nested\").dense_1.trainable = False\n",
        "variable_names_2 = [v.name for v in nested_model.weights]\n",
        "print(variable_names_2)\n",
        "print(\"variable ordering changed:\", variable_names != variable_names_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU0n-jiKgBQW",
        "outputId": "f13c9b0a-27cf-4781-8efb-ef0fcfd88dd7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nested/dense_1/kernel:0', 'nested/dense_1/bias:0', 'nested/dense_2/kernel:0', 'nested/dense_2/bias:0']\n",
            "['nested/dense_2/kernel:0', 'nested/dense_2/bias:0', 'nested/dense_1/kernel:0', 'nested/dense_1/bias:0']\n",
            "variable ordering changed: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer Learning example\n",
        "def create_functional_model():\n",
        "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
        "    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
        "    outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
        "    return keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
        "\n",
        "# Create a model and save its weights in HDF5\n",
        "functional_model = create_functional_model()\n",
        "functional_model.save_weights(\"pretrained_weights.h5\")\n",
        "\n",
        "# Now create a model with the same architecture and load the weights\n",
        "pretrained_model = create_functional_model()\n",
        "pretrained_model.load_weights(\"pretrained_weights.h5\")\n",
        "\n",
        "# Remove the last layer and append a new one\n",
        "extracted_layers = pretrained_model.layers[:-1]\n",
        "extracted_layers.append(keras.layers.Dense(5, name=\"dense_3\"))\n",
        "model = keras.Sequential(extracted_layers)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdSznmm6h9UZ",
        "outputId": "f46f1330-7320-4664-cbb5-c9a0be15570d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,725\n",
            "Trainable params: 54,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}